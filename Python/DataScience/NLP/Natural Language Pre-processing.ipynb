{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CC: Coordinating conjunction\n",
    "\n",
    "CD: Cardinal number\n",
    "\n",
    "DT: Determiner\n",
    "\n",
    "EX: Existential there\n",
    "\n",
    "FW: Foreign word\n",
    "\n",
    "IN: Preposition or subordinating conjunction\n",
    "\n",
    "JJ: Adjective\n",
    "\n",
    "VP: Verb Phrase\n",
    "\n",
    "JJR: Adjective, comparative\n",
    "\n",
    "JJS: Adjective, superlative\n",
    "\n",
    "LS: List item marker\n",
    "\n",
    "MD: Modal\n",
    "\n",
    "NN: Noun, singular or mass\n",
    "\n",
    "NNS: Noun, plural\n",
    "\n",
    "PP: Preposition Phrase\n",
    "\n",
    "NNP: Proper noun, singular Phrase\n",
    "\n",
    "NNPS: Proper noun, plural\n",
    "\n",
    "PDT: Pre determiner\n",
    "\n",
    "POS: Possessive ending\n",
    "\n",
    "PRP: Personal pronoun Phrase\n",
    "\n",
    "PRP: Possessive pronoun Phrase\n",
    "\n",
    "RB: Adverb\n",
    "\n",
    "RBR: Adverb, comparative\n",
    "\n",
    "RBS: Adverb, superlative\n",
    "\n",
    "RP: Particle\n",
    "\n",
    "S: Simple declarative clause\n",
    "\n",
    "SBAR: Clause introduced by a (possibly empty) subordinating conjunction\n",
    "\n",
    "SBARQ: Direct question introduced by a wh-word or a wh-phrase.\n",
    "\n",
    "SINV: Inverted declarative sentence, i.e. one in which the subject follows the tensed verb or modal.\n",
    "\n",
    "SQ: Inverted yes/no question, or main clause of a wh-question, following the wh-phrase in SBARQ.\n",
    "\n",
    "SYM: Symbol\n",
    "\n",
    "VBD: Verb, past tense\n",
    "\n",
    "VBG: Verb, gerund or present participle\n",
    "\n",
    "VBN: Verb, past participle\n",
    "\n",
    "VBP: Verb, non-3rd person singular present\n",
    "\n",
    "VBZ: Verb, 3rd person singular present\n",
    "\n",
    "WDT: Wh-determiner\n",
    "\n",
    "WP: Wh-pronoun\n",
    "\n",
    "WP: Possessive wh-pronoun\n",
    "\n",
    "WRB: Wh-adverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1: Sentence segmentation.\n",
    "reviews = [\"This movie is the best! Will watch it again!\", \"Great Movie! Best one ever.\", \"Love it so much! Will watch, best of the best\"]\n",
    "word_list = []\n",
    "for review in reviews:\n",
    "    review = review.lower()\n",
    "    sentences = nltk.sent_tokenize(review)\n",
    "    for sentence in sentences:\n",
    "        sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) \n",
    "        #Step2: Word Tokenization\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        #Step 3: Predicting parts off speech for each token\n",
    "        tags = nltk.pos_tag(words)\n",
    "        for word in words:   \n",
    "            word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'movie', 'be', 'the', 'best', 'will', 'watch', 'it', 'again', 'great', 'movie', 'best', 'one', 'ever', 'love', 'it', 'so', 'much', 'will', 'watch', 'best', 'of', 'the', 'best']\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Text Lemmatization\n",
    "def compare_stemmer_and_lemmatizer(stemmer, lemmatizer, word, pos):\n",
    "    \"\"\"\n",
    "    Print the results of stemmind and lemmitization using the passed stemmer, lemmatizer, word and pos (part of speech)\n",
    "    \"\"\"\n",
    "#     print(\"Stemmer:\", stemmer.stem(word))\n",
    "#     print(\"Lemmatizer:\", lemmatizer.lemmatize(word, pos))\n",
    "    return lemmatizer.lemmatize(word, pos)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for i in range(len(word_list)):\n",
    "    lem_word = compare_stemmer_and_lemmatizer(stemmer, lemmatizer, word = word_list[i], pos = wordnet.VERB)\n",
    "    if word_list[i] != lem_word:\n",
    "        word_list[i] = lem_word\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie', 'best', 'watch', 'great', 'movie', 'best', 'one', 'ever', 'love', 'much', 'watch', 'best', 'best']\n"
     ]
    }
   ],
   "source": [
    "#Step 5: Remove stop words\n",
    "removed_stop_words = []\n",
    "for word in word_list:\n",
    "    if word not in stopwords.words(\"english\"):\n",
    "        removed_stop_words.append(word)\n",
    "print(removed_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>again</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>great</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>love</th>\n",
       "      <th>movie</th>\n",
       "      <th>much</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>watch</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   again  best  ever  great  is  it  love  movie  much  of  one  so  the  \\\n",
       "0      1     1     0      0   1   1     0      1     0   0    0   0    1   \n",
       "1      0     1     1      1   0   0     0      1     0   0    1   0    0   \n",
       "2      0     2     0      0   0   1     1      0     1   1    0   1    1   \n",
       "\n",
       "   this  watch  will  \n",
       "0     1      1     1  \n",
       "1     0      0     0  \n",
       "2     0      1     1  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "bag_of_words = count_vectorizer.fit_transform(reviews)\n",
    "\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "\n",
    "pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>again</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>great</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>love</th>\n",
       "      <th>movie</th>\n",
       "      <th>much</th>\n",
       "      <th>of</th>\n",
       "      <th>one</th>\n",
       "      <th>so</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>watch</th>\n",
       "      <th>will</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.400294</td>\n",
       "      <td>0.236420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400294</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.400294</td>\n",
       "      <td>0.304434</td>\n",
       "      <td>0.304434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298032</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273916</td>\n",
       "      <td>0.360167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360167</td>\n",
       "      <td>0.360167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360167</td>\n",
       "      <td>0.273916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273916</td>\n",
       "      <td>0.273916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      again      best      ever     great        is        it      love  \\\n",
       "0  0.400294  0.236420  0.000000  0.000000  0.400294  0.304434  0.000000   \n",
       "1  0.000000  0.298032  0.504611  0.504611  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.425441  0.000000  0.000000  0.000000  0.273916  0.360167   \n",
       "\n",
       "      movie      much        of       one        so       the      this  \\\n",
       "0  0.304434  0.000000  0.000000  0.000000  0.000000  0.304434  0.400294   \n",
       "1  0.383770  0.000000  0.000000  0.504611  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.360167  0.360167  0.000000  0.360167  0.273916  0.000000   \n",
       "\n",
       "      watch      will  \n",
       "0  0.304434  0.304434  \n",
       "1  0.000000  0.000000  \n",
       "2  0.273916  0.273916  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "values = tfidf_vectorizer.fit_transform(reviews)\n",
    "\n",
    "# Show the Model as a pandas DataFrame\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "pd.DataFrame(values.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
